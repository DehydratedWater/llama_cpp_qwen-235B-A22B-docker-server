#!/bin/bash

echo "ðŸ§ª Starting llama.cpp Concurrent Performance Test"
echo "=================================================="

# Check if server is running
echo "ðŸ” Checking if llama-server is running..."
if ! curl -s http://localhost:8080/health > /dev/null; then
    echo "âŒ Server not responding at http://localhost:8080"
    echo "ðŸ’¡ Start the server with: docker-compose up -d"
    exit 1
fi

echo "âœ… Server is running!"

# Install dependencies if needed
if ! python3 -c "import aiohttp" 2>/dev/null; then
    echo "ðŸ“¦ Installing required Python packages..."
    pip3 install aiohttp
fi

# Run the test
echo "ðŸš€ Running concurrent test..."
python3 concurrent_test.py

echo "âœ… Test completed!"